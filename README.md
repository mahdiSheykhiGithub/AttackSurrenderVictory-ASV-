# اشاره‌بین
اشاره بین یه مینی پروژه کوچیک برای تشخیص حالات دست با کمک الگوریتم YOLO میباشد. 
# ساخت دیتاست
اولین مرحله این پروژه ساخت دیتاست بود. از آنجایی که این پروژه کاملا شخصی سازی بود بنابراین دیتاست آماده  و مناسبی برای آن موجود نبود پس تصمیم گرفتم خودم تعدادی عکس از صورت و حالات دست خودم تهیه کنم و به کمک سایت roboflow عکس هارو Annotate کنم. ابتدا با فایل capture_Dataset.ipynb تعداد 136 عدد عکس با وبکم لپتاپ گرفتم و سعی کردم به تعداد مساوی عکس از سه حالت مختلف دست تهیه کنم. 
- دست مشت شده به معنای حمله
- دست باز به معنای تسلیم
- دست با دو انگشت بالا به معنای پیروزی
تصاویر هم با دست راست و هم با دست چپ عکس برداری شدند
# سایت roboflow
در مرحله بعد تمام تصاویر را در سایت roboflow بارگذاری کردم و تک به تک عملیات Annotate رو انجام دادم. در نهایت با تکنیک های Augmentation از جمله Flip - Rotation - Shear - Brightness - Noise تعداد عکس هارو به 3 برابر تعداد اصلی افزایش دادم. در خاتمه کار 368 عکس به عنوان دیتاست Generate شد.
# آموزش مدل Train_yolo.ipynb
برای آموزش مدل به سراغ یولو ورژن 8 از نوع small رفتم. حجم کم این مدل باعث صرفه جویی زمانی در بخش آموزش مدل شد. به شکلی که با GPU T4 گوگل کولب در زمان کوتاهی تونستم 100 epoch مدل رو آموزش بدم نهایتا در اخرین epoch نتایج زیر حاصل شد
- Box Loss = 0.3618
- Class Loss = 0.198
- mAP50 = 0.995
- mAP50~95 = 0.858
# آزمایش مدل Test_model.ipynb
برای ازمودن مدل این فایل وبکم لپتاپ رو برای شما باز خواهد کرد و میتونید در شرایط مختلف دستتون رو مقابل دوربین بگیرید و نتیجه رو مشاهده کنید

# فولدر model
در این فولدر نتایج آموزش مدل از جمله نمودار های P-R Curve و F1-Score و سایر نتایج قابل مشاهده است همچنین خود مدل آموزش دیده با نام best.pt در دسترس است
